{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import tensorflow as tf\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "from flwr.common import Metrics\n",
    "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "from flwr.server.strategy import DPFedAvgFixed\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from typing import Optional, Union\n",
    "\n",
    "from flwr.common import EvaluateIns, EvaluateRes, FitIns, FitRes, Parameters, Scalar\n",
    "from flwr.common.dp import add_gaussian_noise\n",
    "from flwr.common.logger import warn_deprecated_feature\n",
    "from flwr.common.parameter import ndarrays_to_parameters, parameters_to_ndarrays\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import DPFedAvgFixed\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from typing import Dict, List, Optional\n",
    "import random\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.criterion import Criterion\n",
    "import threading\n",
    "\n",
    "# Constants\n",
    "VERBOSE = 0\n",
    "NUM_CLIENTS = 100\n",
    "BATCH_SIZE = 16\n",
    "NUM_ROUNDS = 10000\n",
    "CLIP_NORM = 14.142135623730953\n",
    "NOISE_MULTIPLIER = 0.01  # Có thể thay đổi\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def split_mnist_dirichlet_flwr(num_clients=NUM_CLIENTS, alpha=0.5, seed=42):\n",
    "    partitioner = DirichletPartitioner(\n",
    "        num_partitions=num_clients, partition_by=\"label\", alpha=alpha, seed=seed\n",
    "    )\n",
    "    fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": partitioner})\n",
    "    federated_data = {f\"client_{i}\": fds.load_partition(i) for i in range(num_clients)}\n",
    "    return fds, federated_data  # Return both fds and federated_data\n",
    "\n",
    "def write_to_file(filename, data):\n",
    "    \"\"\"Ghi dữ liệu vào file, mỗi dòng là một giá trị mới.\"\"\"\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(f\"{data}\\n\")\n",
    "\n",
    "# Kích hoạt GPU growth\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Create and return MNIST model.\"\"\"\n",
    "    model = MNISTModel()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, trainset, valset) -> None:\n",
    "        self.model = get_model()\n",
    "        self.trainset = trainset\n",
    "        self.valset = valset\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.trainset, epochs=1, verbose=VERBOSE)\n",
    "        return self.model.get_weights(), len(self.trainset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, acc = self.model.evaluate(self.valset, verbose=VERBOSE)\n",
    "        return loss, len(self.valset), {\"accuracy\": acc}\n",
    "\n",
    "def get_client_fn(dataset: FederatedDataset):\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        client_dataset = dataset.load_partition(int(cid), \"train\")\n",
    "        splits = client_dataset.train_test_split(test_size=0.1)\n",
    "        trainset = splits[\"train\"].to_tf_dataset(columns=\"image\", label_cols=\"label\", batch_size=BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        valset = splits[\"test\"].to_tf_dataset(columns=\"image\", label_cols=\"label\", batch_size=BATCH_SIZE*2).prefetch(tf.data.AUTOTUNE)\n",
    "        return FlowerClient(trainset, valset).to_client()\n",
    "    return client_fn\n",
    "class SimpleClientManager(ClientManager):\n",
    "    def __init__(self) -> None:\n",
    "        self.clients: Dict[str, ClientProxy] = {}\n",
    "        self._cv = threading.Condition()\n",
    "        self.seed = 0 # cài đặt seed để fix client tham gia mỗi round\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.clients)\n",
    "\n",
    "    def num_available(self) -> int:\n",
    "        return len(self)\n",
    "\n",
    "    def wait_for(self, num_clients: int, timeout: int = 86400) -> bool:\n",
    "        with self._cv:\n",
    "            return self._cv.wait_for(\n",
    "                lambda: len(self.clients) >= num_clients, timeout=timeout\n",
    "            )\n",
    "\n",
    "    def register(self, client: ClientProxy) -> bool:\n",
    "        if client.cid in self.clients:\n",
    "            return False\n",
    "\n",
    "        self.clients[client.cid] = client\n",
    "        with self._cv:\n",
    "            self._cv.notify_all()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def unregister(self, client: ClientProxy) -> None:\n",
    "        if client.cid in self.clients:\n",
    "            del self.clients[client.cid]\n",
    "\n",
    "            with self._cv:\n",
    "                self._cv.notify_all()\n",
    "\n",
    "    def all(self) -> Dict[str, ClientProxy]:\n",
    "        return self.clients\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        num_clients: int,\n",
    "        min_num_clients: Optional[int] = None,\n",
    "        criterion: Optional[Criterion] = None,\n",
    "    ) -> List[ClientProxy]:\n",
    "    \n",
    "        if min_num_clients is None:\n",
    "            min_num_clients = num_clients\n",
    "        self.wait_for(min_num_clients)\n",
    "        available_cids = list(self.clients)\n",
    "\n",
    "        if num_clients == 1:\n",
    "            sampled_cids = random.sample(available_cids, num_clients)\n",
    "            return [self.clients[cid] for cid in sampled_cids]\n",
    "        \n",
    "        sampled_cids = random.sample(available_cids, num_clients)\n",
    "        self.seed +=1\n",
    "        return [self.clients[cid] for cid in sampled_cids]\n",
    "\n",
    "def main():\n",
    "    mnist_fds, federated_data = split_mnist_dirichlet_flwr()\n",
    "    client_manager = SimpleClientManager()\n",
    "    strategy = DPFedAvgFixed(\n",
    "        fl.server.strategy.FedAvg(\n",
    "            fraction_fit=0.1,\n",
    "            fraction_evaluate=0.05,\n",
    "            min_fit_clients=10,\n",
    "            min_evaluate_clients=5,\n",
    "            min_available_clients=int(NUM_CLIENTS * 0.75),\n",
    "        ),\n",
    "        num_sampled_clients=10,\n",
    "        server_side_noising=True,\n",
    "        clip_norm=CLIP_NORM,\n",
    "        noise_multiplier=NOISE_MULTIPLIER  \n",
    "    )\n",
    "    \n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=get_client_fn(mnist_fds),\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "        strategy=strategy,\n",
    "        client_manager=client_manager,\n",
    "        client_resources={\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Training completed successfully\")\n",
    "    print(history)\n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
